import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv("Big Profit Players in world.csv")


df


#prediksi harga saham
sns.set(style="whitegrid", palette="muted", font_scale=1.1)
%matplotlib inline


print(df.info())
print(df.describe())


print(df.duplicated().sum())
print("Jumlah duplikat:", df.duplicated().sum())


# Distribusi earnings TTM
plt.figure(figsize=(8, 5))
sns.histplot(df['earnings TTM (USD) in Billion'], bins=50, kde=True)
plt.title('Distribusi Earnings TTM')
plt.show()

# Distribusi share price
plt.figure(figsize=(8, 5))
sns.histplot(df['Share price (USD)'], bins=50, kde=True, color='orange')
plt.title('Distribusi Share Price')
plt.show()

# Boxplot untuk mendeteksi outlier
plt.figure(figsize=(8, 5))
sns.boxplot(x=df['earnings TTM (USD) in Billion'])
plt.title('Boxplot Earnings TTM')
plt.show()

plt.figure(figsize=(8, 5))
sns.boxplot(x=df['Share price (USD)'])
plt.title('Boxplot Share Price')
plt.show()


# Scatter plot earnings vs share price
plt.figure(figsize=(8, 6))
sns.scatterplot(x='earnings TTM (USD) in Billion', y='Share price (USD)', data=df)
plt.title('Earnings TTM vs Share Price')
plt.show()

# Jika earnings TTM banyak negatif / skewed, coba plot log(earnings)
df['log_earnings'] = np.log1p(df['earnings TTM (USD) in Billion'].abs())  # log1p untuk menghindari log(0)

plt.figure(figsize=(8, 6))
sns.scatterplot(x='log_earnings', y='Share price (USD)', data=df)
plt.title('Log(Earnings TTM) vs Share Price')
plt.show()


# Banyaknya perusahaan per negara
plt.figure(figsize=(10, 6))
df['Company origin'].value_counts().head(20).plot(kind='bar')
plt.title('Top 20 Company Origin by Count')
plt.ylabel('Number of Companies')
plt.show()

# Rata-rata share price per negara
plt.figure(figsize=(10, 6))
country_mean = df.groupby('Company origin')['Share price (USD)'].mean().sort_values(ascending=False).head(20)
country_mean.plot(kind='bar', color='green')
plt.title('Top 20 Company Origin by Mean Share Price')
plt.ylabel('Mean Share Price')
plt.show()


# Korelasi matrix
corr = df[['earnings TTM (USD) in Billion', 'log_earnings', 'Share price (USD)']].corr()

plt.figure(figsize=(6, 4))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()


print("\n=== Earnings TTM - Statistik deskriptif ===")
print(df['earnings TTM (USD) in Billion'].describe())

print("\n=== Share price - Statistik deskriptif ===")
print(df['Share price (USD)'].describe())

# Skewness & kurtosis
print("\n=== Skewness & Kurtosis ===")
print(f"Earnings TTM skewness: {df['earnings TTM (USD) in Billion'].skew():.2f}")
print(f"Share price skewness: {df['Share price (USD)'].skew():.2f}")
print(f"Earnings TTM kurtosis: {df['earnings TTM (USD) in Billion'].kurt():.2f}")
print(f"Share price kurtosis: {df['Share price (USD)'].kurt():.2f}")

df['log_earnings'] = np.log1p(df['earnings TTM (USD) in Billion'].abs())

print("\n=== Korelasi numerik ===")
corr = df[['earnings TTM (USD) in Billion', 'log_earnings', 'Share price (USD)']].corr()
print(corr)


print("\n=== Top 10 Company origin by jumlah perusahaan ===")
print(df['Company origin'].value_counts().head(10))

print("\n=== Top 10 rata-rata share price per negara ===")
print(df.groupby('Company origin')['Share price (USD)'].mean().sort_values(ascending=False).head(10))

print("\n=== Insight cepat ===")
if df['earnings TTM (USD) in Billion'].skew() > 1 or df['earnings TTM (USD) in Billion'].skew() < -1:
    print("- Earnings TTM sangat skewed, pertimbangkan log transform.")
else:
    print("- Earnings TTM distribusinya relatif normal.")

if df['Share price (USD)'].skew() > 1 or df['Share price (USD)'].skew() < -1:
    print("- Share price sangat skewed, pertimbangkan scaling atau transform.")
else:
    print("- Share price distribusinya relatif normal.")

print("- Korelasi earnings TTM dengan share price:", f"{corr.loc['earnings TTM (USD) in Billion', 'Share price (USD)']:.2f}")
print("- Korelasi log_earnings dengan share price:", f"{corr.loc['log_earnings', 'Share price (USD)']:.2f}")

print("- Negara dengan rata-rata harga saham tertinggi:", df.groupby('Company origin')['Share price (USD)'].mean().idxmax())


def detect_outlier_bounds(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return lower, upper


# Earnings TTM
earnings_lower, earnings_upper = detect_outlier_bounds(df['earnings TTM (USD) in Billion'])
print(f"Earnings TTM lower: {earnings_lower:.2e}, upper: {earnings_upper:.2e}")

# Share price
price_lower, price_upper = detect_outlier_bounds(df['Share price (USD)'])
print(f"Share price lower: {price_lower:.2f}, upper: {price_upper:.2f}")


df['earnings_ttm_winsor'] = np.where(
    df['earnings TTM (USD) in Billion'] < earnings_lower, earnings_lower,
    np.where(df['earnings TTM (USD) in Billion'] > earnings_upper, earnings_upper,
             df['earnings TTM (USD) in Billion'])
)


df['share_price_winsor'] = np.where(
    df['Share price (USD)'] > price_upper, price_upper,
    df['Share price (USD)']
)


df['log_earnings_ttm'] = np.log1p(df['earnings_ttm_winsor'].abs())
df['log_share_price'] = np.log1p(df['share_price_winsor'])


print("\n=== Statistik earnings_ttm_winsor ===")
print(df['earnings_ttm_winsor'].describe())

print("\n=== Statistik share_price_winsor ===")
print(df['share_price_winsor'].describe())

print("\n=== Statistik log transform ===")
print(df[['log_earnings_ttm', 'log_share_price']].describe())


df


print("\n=== Statistik share price ===")
print(df['share_price_winsor'].describe())

print("\n=== Quantiles share price ===")
print(df['share_price_winsor'].quantile([0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]))


median_price = df['share_price_winsor'].median()

low_count = (df['share_price_winsor'] <= median_price).sum()
high_count = (df['share_price_winsor'] > median_price).sum()

print(f"\nJumlah data <= median price ({median_price}): {low_count}")
print(f"Jumlah data > median price: {high_count}")


df['price_bin'] = pd.qcut(df['share_price_winsor'], q=3, labels=['low', 'medium', 'high'])

print("\n=== Distribusi price_bin ===")
print(df['price_bin'].value_counts())


from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor


class FeatureEngineer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None): 
        self.median_name_length_ = X['Company'].apply(lambda x: len(str(x))).median()
        self.top_5_countries_ = X['Company origin'].value_counts().head(5).index.tolist()
        return self
    
    def transform(self, X):
        X_ = X.copy()
        X_['abs_earnings'] = X_['earnings TTM (USD) in Billion'].abs()
        X_['is_loss'] = (X_['earnings TTM (USD) in Billion'] < 0).astype(int)
        X_['earnings_per_rank'] = X_['earnings TTM (USD) in Billion'] / (X_['Rank'] + 1)
        X_['is_high_rank'] = (X_['Rank'] <= X_['Rank'].quantile(0.1)).astype(int)
        X_['log_rank'] = np.log1p(X_['Rank'])
        X_['company_name_length'] = X_['Company'].apply(lambda x: len(str(x)))
        X_['log_abs_earnings'] = np.log1p(X_['abs_earnings'])
        X_['abs_earnings_per_rank'] = X_['abs_earnings'] / (X_['Rank'] + 1)
        X_['log_earnings_per_rank'] = np.log1p(np.abs(X_['earnings_per_rank']))
        X_['is_large_company_name'] = (X_['company_name_length'] > self.median_name_length_).astype(int)
        X_['company_name_vowel_ratio'] = X_['Company'].apply(
            lambda name: sum(1 for c in str(name).lower() if c in 'aeiou') / (len(str(name))+1e-6)
        )
        X_['company_name_has_number'] = X_['Company'].apply(
            lambda name: any(char.isdigit() for char in str(name))
        ).astype(int)
        X_['is_usa'] = (X_['Company origin'] == 'United States').astype(int)
        X_['is_top_5_country'] = X_['Company origin'].apply(lambda x: int(x in self.top_5_countries_))

        return X_


class Winsorizer(BaseEstimator, TransformerMixin):
    def __init__(self, lower, upper): self.lower = lower; self.upper = upper
    def fit(self, X, y=None): return self
    def transform(self, X): return np.clip(X, self.lower, self.upper)


class LogTransformer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None): return self
    def transform(self, X): return np.log1p(np.abs(X))


numeric_features = [
    'earnings TTM (USD) in Billion',
    'abs_earnings',
    'is_loss',
    'earnings_per_rank',
    'log_rank',
    'company_name_length',
    'log_abs_earnings',
    'abs_earnings_per_rank',
    'log_earnings_per_rank',
    'is_large_company_name',
    'company_name_vowel_ratio',
    'company_name_has_number',
    'is_usa',
    'is_top_5_country',
    'is_high_rank'
]
categorical_features = ['Company origin', 'Stock Symbol']


earnings_lower, earnings_upper = -7.21e+08, 1.18e+09


earnings_pipeline = Pipeline([
    ('winsor', Winsorizer(earnings_lower, earnings_upper)),
    ('log', LogTransformer()),
    ('scaler', StandardScaler())
])


abs_earnings_pipeline = Pipeline([
    ('log', LogTransformer()),
    ('scaler', StandardScaler())
])


simple_scaler = Pipeline([
    ('scaler', StandardScaler())
])


categorical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])


preprocessor = ColumnTransformer([
    ('earnings', earnings_pipeline, ['earnings TTM (USD) in Billion']),
    ('abs_earnings', abs_earnings_pipeline, ['abs_earnings']),
    ('simple', simple_scaler, [
        'is_loss', 'earnings_per_rank', 'log_rank', 'company_name_length',
        'log_abs_earnings', 'abs_earnings_per_rank', 'log_earnings_per_rank',
        'is_large_company_name', 'company_name_vowel_ratio',
        'company_name_has_number', 'is_usa', 'is_top_5_country', 'is_high_rank'
    ]),
    ('categorical', categorical_pipeline, categorical_features)
])


models = {
    'LinearRegression': LinearRegression(),
    'RandomForest': RandomForestRegressor(
        random_state=42, n_estimators=50,
        max_depth=5, min_samples_leaf=10, n_jobs=-1
    ),
    'XGBoost': XGBRegressor(
        random_state=42, n_estimators=50,
        max_depth=5, learning_rate=0.1,
        subsample=0.8, colsample_bytree=0.8,
        reg_alpha=0.5, reg_lambda=0.5,
        verbosity=0, n_jobs=-1
    )
}


X = df.copy()
y = df['share_price_winsor'].values


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


for name, model in models.items():
    print(f"\n=== {name} ===")
    
    # Pipeline
    pipe = Pipeline([
        ('feature_engineer', FeatureEngineer()),
        ('preprocessor', preprocessor),
        ('regressor', model)
    ])
    
    # Fit
    pipe.fit(X_train, y_train)
    
    # Predict
    y_pred = pipe.predict(X_test)
    
    # Evaluate
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    
    print(f"MAE : {mae:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"R²  : {r2:.4f}")


import tensorflow as tf
from tensorflow.keras import layers, models


class FeatureEngineer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None): 
        self.median_name_length_ = X['Company'].apply(lambda x: len(str(x))).median()
        self.top_5_countries_ = X['Company origin'].value_counts().head(5).index.tolist()
        return self
    
    def transform(self, X):
        X_ = X.copy()
        X_['abs_earnings'] = X_['earnings TTM (USD) in Billion'].abs()
        X_['is_loss'] = (X_['earnings TTM (USD) in Billion'] < 0).astype(int)
        X_['earnings_per_rank'] = X_['earnings TTM (USD) in Billion'] / (X_['Rank'] + 1)
        X_['is_high_rank'] = (X_['Rank'] <= X_['Rank'].quantile(0.1)).astype(int)
        X_['log_rank'] = np.log1p(X_['Rank'])
        X_['company_name_length'] = X_['Company'].apply(lambda x: len(str(x)))
        # Fitur tambahan aman
        X_['log_abs_earnings'] = np.log1p(X_['abs_earnings'])
        X_['abs_earnings_per_rank'] = X_['abs_earnings'] / (X_['Rank'] + 1)
        X_['log_earnings_per_rank'] = np.log1p(np.abs(X_['earnings_per_rank']))
        X_['is_large_company_name'] = (X_['company_name_length'] > self.median_name_length_).astype(int)
        X_['company_name_vowel_ratio'] = X_['Company'].apply(
            lambda name: sum(1 for c in str(name).lower() if c in 'aeiou') / (len(str(name))+1e-6)
        )
        X_['company_name_has_number'] = X_['Company'].apply(
            lambda name: any(char.isdigit() for char in str(name))
        ).astype(int)
        X_['is_usa'] = (X_['Company origin'] == 'United States').astype(int)
        X_['is_top_5_country'] = X_['Company origin'].apply(lambda x: int(x in self.top_5_countries_))
        return X_


numeric_features = [
    'earnings TTM (USD) in Billion',
    'abs_earnings',
    'is_loss',
    'earnings_per_rank',
    'log_rank',
    'company_name_length',
    'log_abs_earnings',
    'abs_earnings_per_rank',
    'log_earnings_per_rank',
    'is_large_company_name',
    'company_name_vowel_ratio',
    'company_name_has_number',
    'is_usa',
    'is_top_5_country',
    'is_high_rank'
]
categorical_features = ['Company origin', 'Stock Symbol']

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numeric_features),
    ('cat', Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(handle_unknown='ignore'))
    ]), categorical_features)
])


def build_nn(input_dim):
    model = models.Sequential([
        layers.Dense(128, activation='relu', input_dim=input_dim),
        layers.Dense(64, activation='relu'),
        layers.Dense(32, activation='relu'),
        layers.Dense(1)  # output
    ])
    model.compile(optimizer='adam', loss='mean_absolute_error')
    return model


X = df.copy()
y = df['share_price_winsor'].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


full_pipeline = Pipeline([
    ('feature_engineer', FeatureEngineer()),
    ('preprocessor', preprocessor)
])

X_train_prepared = full_pipeline.fit_transform(X_train)
X_test_prepared = full_pipeline.transform(X_test)


input_dim = X_train_prepared.shape[1]
nn = build_nn(input_dim)

history = nn.fit(
    X_train_prepared, y_train,
    epochs=100, batch_size=32,
    validation_split=0.1, verbose=0
)


y_pred = nn.predict(X_test_prepared).flatten()


mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\n=== Neural Network ===")
print(f"MAE : {mae:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"R²  : {r2:.4f}")


def build_deep_nn(input_dim):
    model = models.Sequential([
        layers.Input(shape=(input_dim,)),

        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),

        layers.Dense(128, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),

        layers.Dense(64, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.2),

        layers.Dense(32, activation='relu'),
        layers.BatchNormalization(),

        layers.Dense(1)  # regression output
    ])

    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-5)

    model.compile(optimizer=optimizer, loss='mean_absolute_error')
    return model


y = df['share_price_winsor'].values
X = df.copy()


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


full_pipeline = Pipeline([
    ('feature_engineer', FeatureEngineer()),
    ('preprocessor', preprocessor)
])


X_train_prepared = full_pipeline.fit_transform(X_train)
X_test_prepared = full_pipeline.transform(X_test)


input_dim = X_train_prepared.shape[1]
deep_nn = build_deep_nn(input_dim)


from tensorflow.keras import layers, models, callbacks



early_stop = callbacks.EarlyStopping(
    monitor='val_loss', patience=10,
    restore_best_weights=True
)


history = deep_nn.fit(
    X_train_prepared, y_train,
    epochs=100, batch_size=32,
    validation_split=0.1,
    verbose=1
)


y_pred = deep_nn.predict(X_test_prepared).flatten()

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\n=== Deep Neural Network ===")
print(f"MAE : {mae:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"R²  : {r2:.4f}")


plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('MAE Loss')
plt.title('Training & Validation Loss')
plt.legend()
plt.show()


df



df


df['abs_earnings'] = df['earnings TTM (USD) in Billion'].abs()
df['is_loss'] = (df['earnings TTM (USD) in Billion'] < 0).astype(int)
df['log_earnings'] = np.log1p(df['earnings TTM (USD) in Billion'].clip(lower=0))
df['earnings_per_rank'] = df['earnings TTM (USD) in Billion'] / (df['Rank'] + 1)
df['is_high_rank'] = (df['Rank'] <= df['Rank'].quantile(0.1)).astype(int)
df['log_rank'] = np.log1p(df['Rank'])
df['company_name_length'] = df['Company'].apply(lambda x: len(str(x)))
df['symbol_length'] = df['Stock Symbol'].apply(lambda x: len(str(x)))
df['has_dot_in_symbol'] = df['Stock Symbol'].apply(lambda x: int('.' in str(x)))
df['company_name_word_count'] = df['Company'].apply(lambda x: len(str(x).split()))
df['rank_squared'] = df['Rank'] ** 2
df['rank_cubed'] = df['Rank'] ** 3
df['earnings_squared'] = df['earnings TTM (USD) in Billion'] ** 2
df['earnings_cubed'] = df['earnings TTM (USD) in Billion'] ** 3
df['abs_log_earnings'] = df['log_earnings'].abs()
df['rank_times_earnings'] = df['Rank'] * df['earnings TTM (USD) in Billion']
df['rank_div_earnings'] = df['Rank'] / (df['earnings TTM (USD) in Billion'].abs() + 1e-6)
df['country_name_length'] = df['Company origin'].apply(lambda x: len(str(x)))


from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Dropout


# Target
target = 'share_price_winsor'

# Split data
X = df.drop(columns=[target, 'Share price (USD)'])  # drop target & raw price
y = df[target]

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Identify columns
num_cols = X.select_dtypes(include=['float64', 'int64']).columns
cat_cols = ['Company origin']  # bisa tambahkan kolom kategorikal lain jika ada

# Column transformer
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
])

# Pipeline
pipeline = Pipeline([
    ('preprocessing', preprocessor)
])

# Transform
X_train_proc = pipeline.fit_transform(X_train)
X_val_proc = pipeline.transform(X_val)

# Build NN model (agak kompleks)
model = Sequential([
    Dense(256, activation='relu', input_shape=(X_train_proc.shape[1],)),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(1)
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='mean_absolute_error')


df


history = model.fit(X_train_proc, y_train,
                    validation_data=(X_val_proc, y_val),
                    epochs=100,
                    batch_size=32,
                    verbose=1)


y_pred = model.predict(X_val_proc)
mae = mean_absolute_error(y_val, y_pred)
rmse = np.sqrt(mean_squared_error(y_val, y_pred))
r2 = r2_score(y_val, y_pred)

print("\n=== NN Evaluation ===")
print(f"MAE : {mae:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"R²  : {r2:.4f}")



