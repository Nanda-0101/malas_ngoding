import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv('2026 QS World University Rankings.csv')
df


print(df.info())
print(df.describe())


rank_cols = [col for col in df.columns if 'RANK' in col or col in ['2026 Rank', 'Previous Rank']]
rank_cols


for col in rank_cols:
    print(f'\nUnique values in {col}:')
    print(df[col].unique()[:20])


print('\nUnique values in Overall SCORE:')
print(df['Overall SCORE'].unique()[:20])


def clean_rank(x):
    if pd.isna(x):
        return np.nan
    if isinstance(x, str):
        x = x.replace('+','').replace('=','').strip()
        if x.isdigit():
            return int(x)
    return np.nan

for col in rank_cols:
    df[col] = df[col].apply(clean_rank)


def to_float(x):
    try:
        return float(x)
    except:
        return np.nan

df['Overall SCORE'] = df['Overall SCORE'].apply(to_float)


df


print('\nMissing values per column:')
print(df.isnull().sum())


for col in ['Size', 'Research', 'Status']:
    df[col] = df[col].fillna(df[col].mode()[0])


num_cols = ['IFR SCORE', 'ISR SCORE', 'ISD SCORE', 'IRN SCORE', 'SUS SCORE']
for col in num_cols:
    df[col] = df[col].fillna(df[col].median())


print('\nData after cleaning:')
print(df.info())


rank_cols = ['2026 Rank', 'Previous Rank', 'AR RANK', 'ER RANK', 'FSR RANK',
             'CPF RANK', 'IFR RANK', 'ISR RANK', 'ISD RANK', 'IRN RANK', 
             'EO RANK', 'SUS RANK']


print(df[rank_cols].dtypes)


for col in rank_cols:
    df[col] = df[col].fillna(df[col].median())


cat_cols = ['Size', 'Status', 'Research']
for col in cat_cols:
    df[col] = df[col].fillna(df[col].mode()[0])


df = df.dropna(subset=['2026 Rank', 'Overall SCORE'])


df


from sklearn.preprocessing import LabelEncoder, StandardScaler


encode_cols = ['Country/Territory', 'Region', 'Size', 'Focus', 'Research', 'Status']
le_dict = {}
for col in encode_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    le_dict[col] = le 


scaler = StandardScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])


print('\nâœ… Data sudah siap:')
print(df.info())
print(df.head())


sns.set(style='whitegrid', palette='pastel', font_scale=1.1)


plt.figure(figsize=(8,4))
sns.histplot(df['2026 Rank'], bins=30, kde=True, color='skyblue')
plt.title('Distribusi 2026 Rank')
plt.xlabel('2026 Rank')
plt.ylabel('Count')
plt.show()


plt.figure(figsize=(8,4))
sns.histplot(df['Overall SCORE'], bins=30, kde=True, color='salmon')
plt.title('Distribusi Overall SCORE')
plt.xlabel('Overall SCORE')
plt.ylabel('Count')
plt.show()


plt.figure(figsize=(8,4))
sns.histplot(df['AR SCORE'], bins=30, kde=True, color='green')
plt.title('Distribusi AR SCORE')
plt.xlabel('AR SCORE')
plt.ylabel('Count')
plt.show()


plt.figure(figsize=(16,12))
corr = df.corr(numeric_only=True)
sns.heatmap(corr, annot=False, cmap='coolwarm', linewidths=0.5)
plt.title('Heatmap Korelasi antar Fitur')
plt.show()


target_corr = corr['2026 Rank'].sort_values(ascending=False)
print('Korelasi fitur dengan 2026 Rank:\n')
print(target_corr)


print("====== Deskripsi Statistik ======")
print(df.describe())

print("\n====== Korelasi antar fitur numerik ======")
corr = df.corr(numeric_only=True)
print(corr)

print("\n====== Korelasi fitur dengan target (2026 Rank) ======")
target_corr = corr['2026 Rank'].sort_values(ascending=False)
print(target_corr)

print("\n====== Distribusi Ringkas Rank ======")
print("2026 Rank:")
print(f"  Mean  : {df['2026 Rank'].mean():.2f}")
print(f"  Median: {df['2026 Rank'].median():.2f}")
print(f"  Std   : {df['2026 Rank'].std():.2f}")
print(f"  Min   : {df['2026 Rank'].min():.0f}")
print(f"  Max   : {df['2026 Rank'].max():.0f}")

print("\nOverall SCORE:")
print(f"  Mean  : {df['Overall SCORE'].mean():.2f}")
print(f"  Median: {df['Overall SCORE'].median():.2f}")
print(f"  Std   : {df['Overall SCORE'].std():.2f}")
print(f"  Min   : {df['Overall SCORE'].min():.2f}")
print(f"  Max   : {df['Overall SCORE'].max():.2f}")

print("\n====== Top 5 Korelasi Positif dengan 2026 Rank ======")
print(target_corr.head(5))

print("\n====== Top 5 Korelasi Negatif dengan 2026 Rank ======")
print(target_corr.tail(5))



from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor


from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score


# Cek distribusi rank (target)
print("====== Distribusi Target (2026 Rank) ======")
print(df['2026 Rank'].describe())

# Histogram ringkas pakai value_counts bin
bins = [0,100,200,300,400,500,600,700,800]
counts = pd.cut(df['2026 Rank'], bins).value_counts().sort_index()
print("\n====== Jumlah data per interval Rank ======")
print(counts)


# Hitung IQR target
Q1 = df['2026 Rank'].quantile(0.25)
Q3 = df['2026 Rank'].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = df[(df['2026 Rank'] < lower_bound) | (df['2026 Rank'] > upper_bound)]
print(f"Jumlah data di luar batas IQR (outlier): {len(outliers)}")

# Z-score
from scipy.stats import zscore
z_scores = zscore(df['2026 Rank'])
extreme = df[np.abs(z_scores) > 3]
print(f"Jumlah data dengan Z-score > 3 (potensi noise): {len(extreme)}")

# Cek distribusi fitur numerik juga
print("\nDescriptive stats fitur numerik:")
print(df[['Previous Rank','Country/Territory','Region','Size','Focus','Research','Status']].describe())



target = '2026 Rank'
features = [
    'Previous Rank', 'Country/Territory', 'Region',
    'Size', 'Focus', 'Research', 'Status'
]


X = df[features]
y = df[target]


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


numeric_features = ['Previous Rank']
categorical_features = ['Country/Territory', 'Region', 'Size', 'Focus', 'Research', 'Status']

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
])


pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', XGBRegressor(n_estimators=100, random_state=42))
])


from sklearn.model_selection import train_test_split, GridSearchCV


pipeline.fit(X_train, y_train)


y_pred = pipeline.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\n====== EVALUATION METRICS (Antiâ€‘Leakage Model) ======")
print(f"MAE : {mae:.2f}")
print(f"R^2 : {r2:.4f}")


from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.linear_model import Ridge
from sklearn.ensemble import GradientBoostingRegressor
import lightgbm as lgb
import catboost as cb


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Preprocessing
preprocessing = ColumnTransformer([
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
])

# Define models & params
models = {
    'Ridge': {
        'regressor': Ridge(),
        'params': {'regressor__alpha': [0.1, 1.0, 10]}
    },
    'GradientBoosting': {
        'regressor': GradientBoostingRegressor(random_state=42),
        'params': {'regressor__n_estimators': [100, 200], 'regressor__max_depth': [3, 5]}
    },
    'LightGBM': {
        'regressor': lgb.LGBMRegressor(random_state=42),
        'params': {'regressor__n_estimators': [100, 200], 'regressor__max_depth': [-1, 5]}
    },
    'CatBoost': {
        'regressor': cb.CatBoostRegressor(verbose=0, random_state=42),
        'params': {'regressor__iterations': [100, 200], 'regressor__depth': [4, 6]}
    }
}

results = []



for name, cfg in models.items():
    pipe = Pipeline([
        ('preprocessing', preprocessing),
        ('regressor', cfg['regressor'])
    ])

    grid = GridSearchCV(pipe, cfg['params'], cv=3, scoring='neg_mean_absolute_error')
    grid.fit(X_train, y_train)

    y_pred = grid.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    results.append({'Model': name, 'Best Params': grid.best_params_, 'MAE': mae, 'R2': r2})



df_results = pd.DataFrame(results)
print("\n====== Hasil Perbandingan Model ======")
print(df_results)


import joblib


import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split, GridSearchCV

# Contoh data dummy
data = {
    'Previous Rank': [120, 150, 90, 200],
    'Research': [75.3, 60.2, 88.1, 45.7],
    'Focus': [2, 1, 3, 1],
    'Industry Income': [55.1, 42.5, 70.3, 35.0],
    'Country/Territory': ['United Kingdom', 'Germany', 'United States', 'France'],
    'Region': ['Europe', 'Europe', 'North America', 'Europe'],
    'Size': ['Large', 'Medium', 'Large', 'Small'],
    'Rank': [130, 160, 85, 210]  # Target
}

df = pd.DataFrame(data)

# Fitur & target
target = 'Rank'
num_features = ['Previous Rank', 'Research', 'Focus', 'Industry Income']
cat_features = ['Country/Territory', 'Region', 'Size']

X = df[num_features + cat_features]
y = df[target]

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocessing
preprocessing = ColumnTransformer([
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
])

# Pipeline lengkap
pipeline = Pipeline([
    ('preprocessing', preprocessing),
    ('regressor', GradientBoostingRegressor())
])

# Hyperparameter tuning (contoh singkat)
param_grid = {
    'regressor__n_estimators': [50, 100],
    'regressor__max_depth': [3, 4]
}

grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_absolute_error')
grid.fit(X_train, y_train)

# Best pipeline sudah siap pakai
best_model = grid.best_estimator_



def get_user_input():
    print("=== Input Data Universitas ===")
    previous_rank = float(input("Masukkan nilai 'Previous Rank': "))
    research = float(input("Masukkan nilai 'Research': "))
    focus = int(input("Masukkan nilai 'Focus': "))
    industry_income = float(input("Masukkan nilai 'Industry Income': "))
    country = input("Masukkan kategori 'Country/Territory': ")
    region = input("Masukkan kategori 'Region': ")
    size = input("Masukkan kategori 'Size': ")
    
    data = {
        'Previous Rank': [previous_rank],
        'Research': [research],
        'Focus': [focus],
        'Industry Income': [industry_income],
        'Country/Territory': [country],
        'Region': [region],
        'Size': [size]
    }
    return pd.DataFrame(data)



def predict_university_rank(model, input_df):
    pred = model.predict(input_df)
    return pred[0]



# Contoh dummy input
sample_input = pd.DataFrame({
    'Previous Rank': [120],
    'Research': [75.3],
    'Focus': [2],
    'Industry Income': [55.1],
    'Country/Territory': ['United Kingdom'],
    'Region': ['Europe'],
    'Size': ['Large']
})

pred_rank = predict_university_rank(best_model, sample_input)
print(f"\nðŸŽ“ Prediksi Ranking Universitas: {pred_rank:.2f}")




